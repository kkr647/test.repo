---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Kaitlyn Richardson kkr647 SDS348"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---



<div id="data-description" class="section level2">
<h2><strong>#0: Data Description</strong></h2>
<p>My project 2 data is a cross section of patients who visit a physician’s office and the emergency room. I chose this data because I thought the numerical data including patient’s age, sex, race, family income, office visits, ER emissions, hospitalizations and number of chronic illnesses would be interesting to manipulate. Naturally, I have certain biases of how the healthcare system works, and due to the large sample size (4406 observations), I thought this would be a wonderful way of measuring those biases. After conducting many of the statistical analysis, I have to say my data surprised me!</p>
</div>
<div id="manova-testing" class="section level2">
<h2><strong>#1: MANOVA testing</strong></h2>
<pre><code>## $midwest
##              faminc   numchron         age
## faminc    9.6586771 0.13564832 -0.13658281
## numchron  0.1356483 1.78673069  0.04290657
## age      -0.1365828 0.04290657  0.42726777
## 
## $noreast
##              faminc    numchron         age
## faminc   10.2158816 -0.19381540 -0.07021970
## numchron -0.1938154  1.73820834  0.08371719
## age      -0.0702197  0.08371719  0.41221753
## 
## $other
##              faminc   numchron        age
## faminc    5.3985313 -0.2983877 -0.1707334
## numchron -0.2983877  1.9079812  0.0936425
## age      -0.1707334  0.0936425  0.3669977
## 
## $west
##              faminc   numchron        age
## faminc   10.9882793 -0.3293633 -0.1380837
## numchron -0.3293633  1.7582035  0.1328714
## age      -0.1380837  0.1328714  0.4223358</code></pre>
<pre><code>## midwest noreast other west
## statistic 0.4873276 0.5817851 0.6816152 0.7318595
## p.value 2.195673e-49 1.055828e-40 7.923885e-48
6.47021e-34</code></pre>
<pre><code>## $midwest
##              faminc   numchron         age
## faminc    9.6586771 0.13564832 -0.13658281
## numchron  0.1356483 1.78673069  0.04290657
## age      -0.1365828 0.04290657  0.42726777
## 
## $noreast
##              faminc    numchron         age
## faminc   10.2158816 -0.19381540 -0.07021970
## numchron -0.1938154  1.73820834  0.08371719
## age      -0.0702197  0.08371719  0.41221753
## 
## $other
##              faminc   numchron        age
## faminc    5.3985313 -0.2983877 -0.1707334
## numchron -0.2983877  1.9079812  0.0936425
## age      -0.1707334  0.0936425  0.3669977
## 
## $west
##              faminc   numchron        age
## faminc   10.9882793 -0.3293633 -0.1380837
## numchron -0.3293633  1.7582035  0.1328714
## age      -0.1380837  0.1328714  0.4223358</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## region 3 0.016358 12.101 6 8804 1.364e-13 ***
## Residuals 4402
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre><code>## Response faminc :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## region 3 507 169.017 20.016 6.989e-13 ***
## Residuals 4402 37171 8.444
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response numchron :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## region 3 26.3 8.7558 4.8194 0.002368 **
## Residuals 4402 7997.5 1.8168
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre><code>## # A tibble: 4 x 3
##   region  `mean(faminc)` `mean(numchron)`
##   &lt;fct&gt;            &lt;dbl&gt;            &lt;dbl&gt;
## 1 midwest           2.51             1.46
## 2 noreast           2.68             1.49
## 3 other             2.17             1.64
## 4 west              3.12             1.52</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  OFP$faminc and OFP$region 
## 
##         midwest noreast other  
## noreast 0.2079  -       -      
## other   0.0019  3.4e-05 -      
## west    6.7e-06 0.0024  5.0e-14
## 
## P value adjustment method: none</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  OFP$numchron and OFP$region 
## 
##         midwest noreast other  
## noreast 0.64740 -       -      
## other   0.00053 0.00814 -      
## west    0.36993 0.67854 0.03307
## 
## P value adjustment method: none</code></pre>
<pre><code>## [1] 0.3526</code></pre>
<p><em>Explaination: For MANOVA, one needs to look at multiple assumptions: multivariate normality, homogeneity of within group covariance matrices, linear relationship, etc. For time purposes, I focused on the multivariate normality and homogeneity of covariances. The mshapiro test brought back very, very small p values. The homogeniety of covariances also brought back very strange results (appearing to have differences within groups). Both suggest that the null hypothesis was going to end up being rejected. Initially, when I ran the MANOVA I got a very small p value that would confirm my suspicions that there does appear to be differences in regions. In order to find which areas are different, I ran post-hoc t tests. For both t tests, I looked at family income and number of chronic diseases. During the family income, I found the west to have a very small number in comparision to the others. Interestingly for number of chronic illnesses, the region listed as other had smaller numbers. In total, I did 9 tests- similar to what we did in class. Using the slides from class, I took the .05 number that we expect the p value to be to decide whether or not a value is significant or not and divided it by the 9 tests I did. The total was equivalent to our class results: .0056. However, I also included another code from class that we used to run the type 1 error multiple times and it resulted that the possibility of getting a type one error was 0.3772. Even with both numbers, the values suggestion regions are significant; therefore, we should reject the null hypothesis that family income and number of chronic diseases are shared amongst regions of the US.</em></p>
</div>
<div id="randomization-test-on-data" class="section level2">
<h2><strong>#2: Randomization Test on Data</strong></h2>
<pre class="r"><code>summary(aov(age~numchron,data=OFP))</code></pre>
<pre><code>## Df Sum Sq Mean Sq F value Pr(&gt;F)
## numchron 1 17.6 17.587 44.27 3.22e-11 ***
## Residuals 4404 1749.7 0.397
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>pairwise.t.test(OFP$age, OFP$numchron, p.adj = &quot;none&quot;)</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: OFP$age and OFP$numchron
##
## 0 1 2 3 4 5 6 7
## 1 0.03450 - - - - - - -
## 2 6.8e-06 0.00486 - - - - - -
## 3 2.1e-07 0.00014 0.15381 - - - - -
## 4 2.9e-05 0.00182 0.14441 0.69293 - - - -
## 5 0.00365 0.04211 0.44750 0.95467 0.73761 - - -
## 6 0.02013 0.06551 0.24399 0.47651 0.60894 0.49551 - -
## 7 0.60925 0.76261 0.98563 0.86474 0.80594 0.87765
0.65815 -
## 8 0.61770 0.72557 0.88085 0.98709 0.96933 0.97953
0.84646 0.91070
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>#Randomization Test instead of One-Way ANOVA
F_value &lt;- 44.27

Fs &lt;- replicate(5000,{ 
  new &lt;- OFP%&gt;%mutate(age=sample(age)) 
  SSW &lt;- new %&gt;% group_by(numchron) %&gt;% summarize(SSW=sum((age-mean(age))^2)) %&gt;% summarize(sum(SSW)) %&gt;% pull 
  SSB &lt;- new %&gt;% mutate(mean=mean(age)) %&gt;% group_by(numchron) %&gt;% mutate(groupmean=mean(age)) %&gt;%
    summarize(SSB=sum((mean-groupmean)^2)) %&gt;% summarize(sum(SSB))%&gt;% pull 
  (SSB/1)/(SSW/4404) 
  })

#PLOT OF NULL
{hist(Fs, prob=T); abline(v = F_value, col=&quot;red&quot;,add=T)}</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(Fs&gt;F_value)</code></pre>
<pre><code>## [1] 0</code></pre>
<p><em>Explanation: For my project, I chose to use randimization instead of a one-way F-statistic/ANOVA. In order to compare the randomization, I needed to run an ANOVA to get an initial f-statistic. Once I got my f-statistic, I used a randomization event to test 5000 times. Whenever I ran the data, I didn’t get any values that were higher than the intial f-statistic value of 44.27. The mean result ended up being 0. In the plot, one can see that it would be very, very unlikely to get a value over 44.27. Therefore, the results suggested that the null hypothesis needs to be rejected: it is reasonable to claim that the groups are significantly different.</em></p>
</div>
<div id="linear-regression-model" class="section level2">
<h2><strong>#3. Linear Regression Model</strong></h2>
<pre class="r"><code>OFP$hosp_c &lt;- OFP$hosp- mean(OFP$hosp)
OFP$age_c &lt;- OFP$age- mean(OFP$age)
mean_hosp &lt;- mean(OFP$hosp)
mean_hosp</code></pre>
<pre><code>## [1] 0.2959601</code></pre>
<pre class="r"><code>fit&lt;-lm(emr~ age_c * hosp_c, data=OFP)
summary(fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = emr ~ age_c * hosp_c, data = OFP)
##
## Residuals:
## Min 1Q Median 3Q Max
## -3.5968 -0.1500 -0.1219 -0.0985 10.6525
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.265440 0.009339 28.422 &lt;2e-16 ***
## age_c 0.030485 0.014759 2.066 0.0389 *
## hosp_c 0.452812 0.012685 35.695 &lt;2e-16 ***
## age_c:hosp_c -0.055245 0.019761 -2.796 0.0052 **
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.6182 on 4402 degrees of
freedom
## Multiple R-squared: 0.2287, Adjusted R-squared: 0.2281
## F-statistic: 435 on 3 and 4402 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>bptest(fit)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit
## BP = 353.79, df = 3, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>summary(fit)$coef[,1:2]</code></pre>
<pre><code>##                 Estimate  Std. Error
## (Intercept)   0.26543979 0.009339088
## age_c         0.03048482 0.014758990
## hosp_c        0.45281157 0.012685497
## age_c:hosp_c -0.05524472 0.019761255</code></pre>
<pre class="r"><code>coeftest(fit, vcov = vcovHC(fit))[,1:2]</code></pre>
<pre><code>##                 Estimate  Std. Error
## (Intercept)   0.26543979 0.009662447
## age_c         0.03048482 0.015307067
## hosp_c        0.45281157 0.043452669
## age_c:hosp_c -0.05524472 0.059874017</code></pre>
<pre class="r"><code>#GGPLOT REGRESSION SHOWING INTERACTION? 
library(interactions)
interact_plot(fit, hosp_c, age_c, plot.points = T) </code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" />
<em>Explanation: The results from my linear regression model were very interesting and not what I expected at all! When looking at the lm results, it has that mean age and hospitalizations together are negatively related when it comes to ER visits. These same, strange results were even more evident with the ggplot. The lighter -SD of age (representing the younger generation) ended up with higher hospitalizations with ER visits than people of an older age. I believe this data means that younger generations with higher ER visits end up with more hospitalizations than people of an advanced age. A previous test that I did, revealed that older people with more office visits had higher hospitalizations. Perhaps it would be interesting to see with my data if older people get hospitalized more often from a physicians office than an ER. (That’s completely against what I would have expected!) Because my data is discrete, the plot is hard to really define the homoscedasticity. It appears that there are higher amounts of low ER vists and hospitilizations. I also ran a Breush-Pagan test just to be safe; the results were lower than .05 suggest that there is homoskedasticity. So, even though I got a result with homoskedasticity, I decided to continue on just in case with the robust standar errors code. With the robust standard errors, I interpreted my results to still suggest that the null hypothesis should be rejected; however, the values were closer to the 0.05 target. They were slightly less significant. Also, the interaction of the mean age and mean hospitilizations did change to 0.59, making it NO LONGER significant. The use of the standard errors helps make up for errors in homoskedasticity.</em></p>
</div>
<div id="bootstrapping" class="section level2">
<h2><strong>#4. Bootstrapping</strong></h2>
<pre class="r"><code>set.seed(348)

OFP$age_c &lt;- OFP$age - mean(OFP$age)
OFP$hosp_c &lt;- OFP$hosp - mean(OFP$hosp)
boot_dat&lt;- sample_frac(OFP, replace=T)

samp_distn&lt;-replicate(5000, {  
  boot_dat &lt;- sample_frac(OFP, replace=T) 
  fit &lt;- lm(emr~age_c*hosp_c, data=boot_dat)
  coef(fit)
}) 

samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)      age_c     hosp_c age_c:hosp_c
## 1 0.009692156 0.01508432 0.04203412   0.05894238</code></pre>
<pre class="r"><code>samp_distn%&gt;%t%&gt;%as.data.frame%&gt;%gather%&gt;%group_by(key)%&gt;% summarize(lower=quantile(value,.025), upper=quantile(value,.975))</code></pre>
<pre><code>## # A tibble: 4 x 3
##   key              lower  upper
##   &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;
## 1 (Intercept)   0.247    0.284 
## 2 age_c         0.000653 0.0600
## 3 age_c:hosp_c -0.168    0.0670
## 4 hosp_c        0.373    0.539</code></pre>
<p><em>Explanation: My boot-strapping data looks very similar to the data that I got from doing the robust standard errors on question 3. The intercept shows an increase against the other two variables of less than 1%. Age and hosp seem to still be significant; however, age and hosp together is no longer significant. My original data suggested that they were all significant; however, the last two results suggests that perhaps age and hosp together are not significantly different from each other.</em></p>
</div>
<div id="logistic-regression-model" class="section level2">
<h2><strong>#5.Logistic Regression Model</strong></h2>
<p>Fit a logistic regression model predicting a binary variable (if you don’t have one, make/get one) from at least two explanatory variables (interaction not necessary).</p>
<pre><code>- Interpret coefficient estimates in context (10)
- Report a confusion matrix for your logistic regression (5)</code></pre>
<pre class="r"><code>OFP2 &lt;-OFP %&gt;% mutate(y=ifelse(maried==&quot;yes&quot;,1,0))
fit2&lt;-glm(y~ age + numchron, data=OFP2, family=&quot;binomial&quot;(link=&quot;logit&quot;))
coeftest(fit2)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 6.393838 0.387189 16.5135 &lt;2e-16 ***
## age -0.835264 0.052396 -15.9413 &lt;2e-16 ***
## numchron -0.015032 0.023256 -0.6464 0.518
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit2))%&gt;%round(3)</code></pre>
<pre><code>## (Intercept)         age    numchron 
##     598.148       0.434       0.985</code></pre>
<pre class="r"><code>#CONFUSION MATRIX
probs&lt;-predict(fit2,type=&quot;response&quot;)
table(predict=as.numeric(probs&gt;.5),truth=OFP2$y) %&gt;% addmargins</code></pre>
<pre><code>##        truth
## predict    0    1  Sum
##     0    841  536 1377
##     1   1159 1870 3029
##     Sum 2000 2406 4406</code></pre>
<pre class="r"><code>#Accuracy
(841+1870)/4406 #=0.6152973</code></pre>
<pre><code>## [1] 0.6152973</code></pre>
<pre class="r"><code>#Sensitivity(TPR)
(1870/2406)#= 0.7772236</code></pre>
<pre><code>## [1] 0.7772236</code></pre>
<pre class="r"><code>#Specificity (TNR)
(841/2000) #=0.4205</code></pre>
<pre><code>## [1] 0.4205</code></pre>
<pre class="r"><code>#Precision(PPV)
(868/2000) #=0.434</code></pre>
<pre><code>## [1] 0.434</code></pre>
<pre class="r"><code> #ROC
ROCplot&lt;-ggplot(OFP2)+geom_roc(aes(d=maried,m=probs), n.cuts=0)+  geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2) + scale_x_continuous(limits = c(0,1))
ROCplot</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#AUC = POOR :(
calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.6356461</code></pre>
<pre class="r"><code>##ggplot of LOG ODDS
OFP2$logit&lt;-predict(fit2,type=&quot;link&quot;)

OFP2%&gt;%ggplot(aes(logit,color=maried,fill=maried))+geom_density(alpha=.4)+  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab(&quot;predictor (logit)&quot;)+
  ylab(&quot;Density&quot;) + geom_rug(aes(logit))</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" />
<em>The results of my ROC and density plot yet again do not show a strong relationship. Sensitivity is the true positive rate, which was 0.7772236. Specificity is the true negative rate (TNR), which was 0.4205. That’s where the ROC comes in: it allows us to see the trade off of both. My interpretation of the ROC curve being almost equivalent to the AUC of .5, I would say it represents a chance prediction. My suspicisions were confirmed when I did the AUC of the boxplot. It was roughly 0.64 which is just a little over 50%. I interpret that result as still being very poor. On the boxplot, in theory everything past the 0 point would be ideally either married or non married. The graph shows a huge overlap between both.With that being said, you can see a little bit of difference where if the value is less than 0, there is a higher probability that it would be not be married and vice versa. </em></p>
</div>
<div id="lasso" class="section level2">
<h2><strong>6. Lasso</strong></h2>
<pre><code>- Fit model, compute in-sample classification diagnostics (Accuracy, Sensitivity, Specificity, Precision, AUC), and interpret (5)
- Perform 10-fold (or repeated random sub-sampling) CV with the same model and report average out-of-sample classification diagnostics (Accuracy, Sensitivity, Specificity, Precision, and AUC); interpret AUC and compare with the in-sample metrics (10)
- Perform LASSO on the same model/variables. Choose lambda to give the simplest model whose accuracy is near that of the best (i.e., `lambda.1se`). Discuss which variables are retained. (5)
- Perform 10-fold CV using only the variables lasso selected: compare model&#39;s out-of-sample AUC to that of your logistic regressions above (5)</code></pre>
<p>fit3 &lt;- glm(y~., data=OFP2)
class_diag&lt;-function(probs,truth){
if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
tab&lt;-table(factor(probs&gt;.5,levels=c(“FALSE”,“TRUE”)),truth)
prediction&lt;-ifelse(probs&gt;.5,1,0)
acc=mean(truth==prediction)
sens=mean(prediction[truth==1]==1)
spec=mean(prediction[truth==0]==0)
ppv=mean(truth[prediction==1]==1)
f1=2<em>(sens</em>ppv)/(sens+ppv)</p>
<p>#CALCULATE EXACT AUC
ord&lt;-order(probs, decreasing=TRUE)
probs &lt;- probs[ord]; truth &lt;- truth[ord]</p>
<p>TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))</p>
<p>dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)</p>
<p>n &lt;- length(TPR)
auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )</p>
<p>data.frame(acc,sens,spec,ppv,auc)
}</p>
<p>set.seed(1234)
k=10</p>
<p>data &lt;- OFP2 %&gt;% sample_frac #put rows of dataset in random order
folds &lt;- ntile(1:nrow(OFP),n=10) #create fold labels</p>
<p>diags&lt;-NULL
for(i in 1:k){
train &lt;- OFP2[folds!=i,] #create training set (all but fold i)
test &lt;- OFP2[folds==i,] #create test set (just fold i)
truth &lt;- test$y #save truth labels from fold i</p>
<p>fit &lt;- glm(y~(.)^2, data=OFP2, family=“binomial”)
probs &lt;- predict(fit3, newdata=test, type=“response”)</p>
<p>diags&lt;-rbind(diags,class_diag(probs,truth))
}</p>
<p>summarize_all(diags,mean)</p>
<p>OFP2 %&gt;% na.exclude
OFP2 &lt;-OFP %&gt;% mutate(y=ifelse(maried==“yes”,1,0))
model.matrix(y~.,data=OFP2)[,-1]
y&lt;-as.matrix(OFP2$y) #grab response
x&lt;-model.matrix(y~.,data=OFP2)[,-1] #grab predictors
head(x)</p>
<p>cv&lt;-cv.glmnet(x,y,family=“binomial”)
lasso&lt;-glmnet(x,y,family=“binomial”,lambda=cv$lambda.1se)
coef(lasso)</p>
<p>#Apparently only people who are married have a significance</p>
<p>set.seed(1234)
k=10
data &lt;- OFP2 %&gt;% sample_frac
#put rows of dataset in random order
folds &lt;- ntile(1:nrow(OFP2),n=10)
#create fold labels
diags&lt;-NULL
for(i in 1:k){<br />
train &lt;- OFP2[folds!=i,]
#create training set (all but fold i)<br />
test &lt;- OFP2[folds==i,]
#create test set (just fold i)<br />
truth &lt;- test$mariedyes
#save truth labels from fold i<br />
fit &lt;- glm(y~maried, data=OFP2, family=“binomial”)<br />
probs &lt;- predict(fit3, newdata=test, type=“response”)
diags&lt;-rbind(diags,class_diag(probs,truth))
}</p>
<p>diags%&gt;%summarize_all(mean)</p>
<p><em>Unfortunately, I ran out of time to complete this last part of the assignment. No matter how much I played around with my data, I couldn’t get a new response variable from the lasso to re-do the regression. I suppose this error is on my end and the variable I used. Out of desperation, I tried using “age” which is a numerical variable just to see how it would affect the answers; however, I got the same thing back. Due to knitting purposes, I decided to use all of 6 as a comment because I’d rather get partial credit than no credit. I will continue trying to submit an improved question 6. I think because this was the last topic we covered so I’m not as comfortable with this topic as the previous questions. I apologize! </em>
Note that the <code>echo = FALSE</code> parameter was added to the code chunk to prevent printing of the R code that generated the plot.</p>
</div>
